{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ATMS 523\n",
        "## Module 4 Lecture 2\n",
        "\n",
        "### Using a Web API to obtain data\n",
        "\n",
        "This example shows you how to use a web API to obtain data from NCEI.  It is the same dataset we obtained within Module 3, but here we are making small calls to get only the data we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kp6pa5jNqCSX"
      },
      "outputs": [],
      "source": [
        "#needed to make web requests\n",
        "import requests\n",
        "\n",
        "#store the data we get as a dataframe\n",
        "import pandas as pd\n",
        "\n",
        "#convert the response as a strcuctured json\n",
        "import json\n",
        "\n",
        "#mathematical operations on lists\n",
        "import numpy as np\n",
        "\n",
        "#parse the datetimes we get from NOAA\n",
        "from datetime import datetime\n",
        "\n",
        "#import time for sleeping\n",
        "import time\n",
        "\n",
        "#add the access token you got from NOAA # this is snesbitt's so don't mess with it!\n",
        "Token = 'qGhKPoTezWscLZFQAzmnmBzBkrsiwroe'\n",
        "\n",
        "#Enter data type and station ID from inventory - here is GHCND https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
        "station_id = 'GHCND:USC00118740'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bSbsdpEqD5J",
        "outputId": "ba7c34a1-c83e-4685-f705-ff46bd3d6683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "working on year 1905\n",
            "working on year 1906\n",
            "working on year 1907\n",
            "working on year 1908\n",
            "working on year 1909\n",
            "working on year 1910\n",
            "working on year 1911\n",
            "working on year 1912\n",
            "working on year 1913\n",
            "working on year 1914\n",
            "working on year 1915\n",
            "working on year 1916\n",
            "working on year 1917\n"
          ]
        },
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TMIN&datatypeid=TMAX&datatypeid=PRCP&limit=1000&stationid=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mstation_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&startdate=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39myear\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-01-01&enddate=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39myear\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m:Token})\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#load the api response as a json\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#TODO check for empty request\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#get all items in the response which are max&min temperature readings\u001b[39;00m\n\u001b[1;32m     21\u001b[0m maxtemps \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTMAX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pythia/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pythia/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pythia/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "source": [
        "#initialize lists to store data\n",
        "dates_mintemp = []\n",
        "dates_maxtemp = []\n",
        "dates_precip = []\n",
        "min_temps = []\n",
        "max_temps = []\n",
        "precip = []\n",
        "\n",
        "#for each year from 1905-2022 where we know we have data inventory ...\n",
        "for year in range(1905, 2023):\n",
        "    year = str(year)\n",
        "    print('working on year '+year)\n",
        "    \n",
        "    #make the api call\n",
        "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TMIN&datatypeid=TMAX&datatypeid=PRCP&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
        "    #load the api response as a json\n",
        "    d = json.loads(r.text)\n",
        "    #TODO check for empty request\n",
        "\n",
        "    #get all items in the response which are max&min temperature readings\n",
        "    maxtemps = [item for item in d['results'] if item['datatype']=='TMAX']\n",
        "    mintemps = [item for item in d['results'] if item['datatype']=='TMIN']\n",
        "    precips = [item for item in d['results'] if item['datatype']=='PRCP']\n",
        "    #get the date field from all average temperature readings\n",
        "    dates_maxtemp += [item['date'] for item in maxtemps]\n",
        "    dates_mintemp += [item['date'] for item in mintemps]\n",
        "    dates_precip += [item['date'] for item in precips]\n",
        "    #get the actual temperature from the returned data\n",
        "    max_temps += [item['value'] for item in maxtemps]\n",
        "    min_temps += [item['value'] for item in mintemps]\n",
        "    precip += [item['value'] for item in precips]\n",
        "    time.sleep(0.2) # API max 5 requests per second\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZsW99tWrl-e"
      },
      "outputs": [],
      "source": [
        "#initialize dataframe\n",
        "df_temp_min = pd.DataFrame()\n",
        "df_temp_max = pd.DataFrame()\n",
        "df_precip = pd.DataFrame()\n",
        "\n",
        "#populate date and min and max temperature & precip fields (convert string date to datetime)\n",
        "df_temp_min['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_mintemp]\n",
        "df_temp_min['minTemp'] = [float(v)/10.0 for v in min_temps]\n",
        "\n",
        "df_temp_max['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_maxtemp]\n",
        "df_temp_max['maxTemp'] = [float(v)/10.0 for v in max_temps]\n",
        "\n",
        "df_precip['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_precip]\n",
        "df_precip['precip'] = [float(v)/10.0 for v in precip]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpZKUtGAxzrP"
      },
      "outputs": [],
      "source": [
        "#merge the dataframes\n",
        "newdf_all = pd.merge(df_temp_max,df_temp_min, left_index=True, right_index=True)\n",
        "newdf_all = pd.merge(newdf_all, df_precip, left_index=True, right_index=True)\n",
        "newdf_all.drop(columns = ['date_x', 'date_y'], inplace=True)\n",
        "newdf_all = newdf_all.set_index('date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "8v8cZRz75I52",
        "outputId": "da5ff2fa-957b-4692-ce2f-ea715f55f016"
      },
      "outputs": [],
      "source": [
        "newdf_all"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('py3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "7a6b41cc1ffbe7f6292ade58ee9ab0c89bd7fa770a77f101cc95d5710b4e5fa9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
